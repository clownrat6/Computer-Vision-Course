{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "DOWNLOAD_MNIST = True\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(root='./mnist/', train=True, transform=torchvision.transforms.ToTensor(),\n",
    "                                        download=DOWNLOAD_MNIST, )\n",
    "test_data = torchvision.datasets.MNIST(root='./mnist/', train=False)\n",
    "print(train_data.train_data.shape)\n",
    "\n",
    "train_x = torch.unsqueeze(train_data.train_data, dim=1).type(torch.FloatTensor) / 255.\n",
    "train_y = train_data.train_labels\n",
    "print(train_x.shape)\n",
    "\n",
    "test_x = torch.unsqueeze(test_data.test_data, dim=1).type(torch.FloatTensor)[:2000] / 255.  # Tensor on GPU\n",
    "test_y = test_data.test_labels[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModule(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, order='CAB', residual=True):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.order = order\n",
    "        self.residual = residual\n",
    "        \n",
    "        # 'CBA': Conv + BN + Activation\n",
    "        # 'CAB': Conv + Activation + BN\n",
    "        assert self.order in ['CBA', 'CAB']\n",
    "        module_pack = []\n",
    "        module_pack.append(nn.Conv2d(self.in_channels, self.out_channels, kernel_size=3, bias=False, padding=1))\n",
    "        if order == 'CBA':\n",
    "            module_pack.append(nn.BatchNorm2d(self.out_channels))\n",
    "            module_pack.append(nn.ReLU())\n",
    "        else:\n",
    "            module_pack.append(nn.ReLU())  \n",
    "            module_pack.append(nn.BatchNorm2d(self.out_channels))\n",
    "    \n",
    "        self.module = nn.Sequential(*module_pack)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.module(x)\n",
    "\n",
    "        if self.residual:\n",
    "            return out + x\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "\n",
    "class ConvLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, num_blocks, downsampling=True):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_blocks = num_blocks\n",
    "        self.downsampling = downsampling\n",
    "\n",
    "        self.stem = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        blocks = []\n",
    "        for _ in range(num_blocks):\n",
    "            blocks.append(ConvModule(self.out_channels, self.out_channels))\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "\n",
    "        if self.downsampling:\n",
    "            self.downsampling = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.blocks(x)\n",
    "        if self.downsampling:\n",
    "            x = self.downsampling(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, in_channels, base_channels, num_classes, dropout_rate=0.5, stage_blocks=[2, 2]):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.base_channels = base_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for num_blocks in stage_blocks:\n",
    "            self.layers.append(ConvLayer(in_channels, base_channels, num_blocks))\n",
    "            in_channels = base_channels\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.warm_up_linears = nn.Sequential(*[nn.Linear(base_channels, base_channels * 2), nn.Linear(base_channels * 2, base_channels)])\n",
    "        self.out_linear = nn.Linear(base_channels, num_classes)\n",
    "        self.dropout = nn.Dropout2d(1 - self.dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.warm_up_linears(x)\n",
    "        # x = self.dropout(x)\n",
    "        output = self.out_linear(x)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 2.3736 | test accuracy: 0.108\n",
      "Epoch:  0 | train loss: 0.4529 | test accuracy: 0.678\n",
      "Epoch:  0 | train loss: 0.1835 | test accuracy: 0.783\n",
      "Epoch:  0 | train loss: 0.0946 | test accuracy: 0.781\n",
      "Epoch:  1 | train loss: 0.0901 | test accuracy: 0.941\n",
      "Epoch:  1 | train loss: 0.1005 | test accuracy: 0.877\n",
      "Epoch:  1 | train loss: 0.0974 | test accuracy: 0.552\n",
      "Epoch:  1 | train loss: 0.0600 | test accuracy: 0.878\n",
      "Epoch:  2 | train loss: 0.0802 | test accuracy: 0.805\n",
      "Epoch:  2 | train loss: 0.0748 | test accuracy: 0.882\n",
      "Epoch:  2 | train loss: 0.0160 | test accuracy: 0.925\n",
      "Epoch:  2 | train loss: 0.0757 | test accuracy: 0.900\n",
      "Epoch:  3 | train loss: 0.0339 | test accuracy: 0.972\n",
      "Epoch:  3 | train loss: 0.0311 | test accuracy: 0.970\n",
      "Epoch:  3 | train loss: 0.0150 | test accuracy: 0.977\n",
      "Epoch:  3 | train loss: 0.0789 | test accuracy: 0.972\n",
      "Epoch:  4 | train loss: 0.0317 | test accuracy: 0.938\n",
      "Epoch:  4 | train loss: 0.0208 | test accuracy: 0.968\n",
      "Epoch:  4 | train loss: 0.0213 | test accuracy: 0.965\n",
      "Epoch:  4 | train loss: 0.0172 | test accuracy: 0.978\n",
      "max evaluation accuracy: 0.9779999852180481\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 5\n",
    "LR = 0.005\n",
    "data_size = 20000\n",
    "batch_size = 200\n",
    "\n",
    "max_accuracy = -1\n",
    "\n",
    "fc = Classifier(in_channels=1, base_channels=64, num_classes=10)\n",
    "\n",
    "optimizer = torch.optim.Adam(fc.parameters(), lr=LR)\n",
    "# loss_func = nn.MSELoss()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "    random_indx = np.random.permutation(data_size)\n",
    "    for batch_i in range(data_size // batch_size):\n",
    "        indx = random_indx[batch_i * batch_size:(batch_i + 1) * batch_size]\n",
    "\n",
    "        b_x = train_x[indx, :]\n",
    "        b_y = train_y[indx]\n",
    "\n",
    "        output = fc(b_x)\n",
    "        loss = loss_func(output, b_y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch_i % 50 == 0:\n",
    "            fc = fc.eval()\n",
    "            test_output = fc(test_x)\n",
    "            fc = fc.train()\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = torch.sum(pred_y == test_y).type(torch.FloatTensor) / test_y.size(0)\n",
    "            if accuracy > max_accuracy:\n",
    "                max_accuracy = accuracy\n",
    "\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data.cpu().numpy(), '| test accuracy: %.3f' % accuracy)\n",
    "\n",
    "print(f'max evaluation accuracy: {max_accuracy}')\n",
    "\n",
    "# test_output = fc(test_x[:10])\n",
    "# pred_y = torch.max(test_output, 1)[1].data.squeeze()  # move the computation in GPU\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "876897395f832d09eb98abcf3e2d8e1e93855b0e12f2506451f8f6e75b31e667"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('pt1.8': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
